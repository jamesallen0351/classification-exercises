{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "581b2299",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "\n",
    "- 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n",
    "- 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "- 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "- 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "- 5. Run through steps 2-4 using a different max_depth value.\n",
    "\n",
    "- 6. Which model performs better on your in-sample data?\n",
    "\n",
    "- 7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbee16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import prepare\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dead3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('titanic_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec8ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = acquire.get_titanic_data()\n",
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "074c26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203f5098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b840d",
   "metadata": {},
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    This function will drop any duplicate observations, \n",
    "    drop ['deck', 'embarked', 'class', 'age'], fill missing embark_town with 'Southampton'\n",
    "    and create dummy vars from sex and embark_town. \n",
    "    '''\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.drop(columns=['deck', 'embarked', 'class', 'age'])\n",
    "    df['embark_town'] = df.embark_town.fillna(value='Southampton')\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], drop_first=True)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2542a6",
   "metadata": {},
   "source": [
    "def split_data(df):\n",
    "    '''\n",
    "    take in a DataFrame and return train, validate, and test DataFrames; stratify on survived.\n",
    "    return train, validate, test DataFrames.\n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "    train, validate = train_test_split(train_validate, \n",
    "                                       test_size=.3, \n",
    "                                       random_state=123, \n",
    "                                       stratify=train_validate.survived)\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2184eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class     age  sex survived\n",
       "1  1st class  adults  man      yes\n",
       "2  1st class  adults  man      yes\n",
       "3  1st class  adults  man      yes\n",
       "4  1st class  adults  man      yes\n",
       "5  1st class  adults  man      yes"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9ffa6664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>...</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.45</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  passenger_id  survived  pclass     sex   age  sibsp  parch  \\\n",
       "886         886           886         0       2    male  27.0      0      0   \n",
       "887         887           887         1       1  female  19.0      0      0   \n",
       "888         888           888         0       3  female   NaN      1      2   \n",
       "889         889           889         1       1    male  26.0      0      0   \n",
       "890         890           890         0       3    male  32.0      0      0   \n",
       "\n",
       "      fare embarked  ... alone  sex_male  embark_town_Queenstown  \\\n",
       "886  13.00        S  ...     1         1                       0   \n",
       "887  30.00        S  ...     1         0                       0   \n",
       "888  23.45        S  ...     0         0                       0   \n",
       "889  30.00        C  ...     1         1                       0   \n",
       "890   7.75        Q  ...     1         1                       1   \n",
       "\n",
       "     embark_town_Southampton  sex_male  embark_town_Queenstown  \\\n",
       "886                        1         1                       0   \n",
       "887                        1         0                       0   \n",
       "888                        1         0                       0   \n",
       "889                        0         1                       0   \n",
       "890                        0         1                       1   \n",
       "\n",
       "     embark_town_Southampton  sex_male  embark_town_Queenstown  \\\n",
       "886                        1         1                       0   \n",
       "887                        1         0                       0   \n",
       "888                        1         0                       0   \n",
       "889                        0         1                       0   \n",
       "890                        0         1                       1   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "886                        1  \n",
       "887                        1  \n",
       "888                        1  \n",
       "889                        0  \n",
       "890                        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269364d",
   "metadata": {},
   "source": [
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49665a40",
   "metadata": {},
   "source": [
    "def prep_titanic_data(df):\n",
    "    '''\n",
    "    This function takes in a df and will drop any duplicate observations, \n",
    "    drop ['deck', 'embarked', 'class', 'age'], fill missing embark_town with 'Southampton'\n",
    "    create dummy vars from sex and embark_town, and perform a train, validate, test split. \n",
    "    Returns train, validate, and test DataFrames\n",
    "    '''\n",
    "    df = clean_data(df)\n",
    "    train, validate, test = split_data(df)\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb3d4b",
   "metadata": {},
   "source": [
    "train, validate, test = prep_titanic_data(df)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a1ab98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.survived.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "76557c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 891\n",
       "passenger_id               891\n",
       "survived                     2\n",
       "pclass                       3\n",
       "sex                          2\n",
       "age                         88\n",
       "sibsp                        7\n",
       "parch                        7\n",
       "fare                       248\n",
       "embarked                     3\n",
       "class                        3\n",
       "deck                         7\n",
       "embark_town                  3\n",
       "alone                        2\n",
       "sex_male                     2\n",
       "embark_town_Queenstown       2\n",
       "embark_town_Southampton      2\n",
       "sex_male                     2\n",
       "embark_town_Queenstown       2\n",
       "embark_town_Southampton      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7368c647",
   "metadata": {},
   "source": [
    "# What is your baseline prediction? What is your baseline accuracy? \n",
    "### remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n",
    "baseline:  survived = no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b0502f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column names to lowercase, replace '.' in column names with '_'\n",
    "# df.columns = [col.lower().replace('.', '_') for col in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51af923b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class     age  sex survived\n",
       "1  1st class  adults  man      yes\n",
       "2  1st class  adults  man      yes\n",
       "3  1st class  adults  man      yes\n",
       "4  1st class  adults  man      yes\n",
       "5  1st class  adults  man      yes"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0961ddfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1316</td>\n",
       "      <td>1316</td>\n",
       "      <td>1316</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3rd class</td>\n",
       "      <td>adults</td>\n",
       "      <td>man</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>706</td>\n",
       "      <td>1207</td>\n",
       "      <td>869</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            class     age   sex survived\n",
       "count        1316    1316  1316     1316\n",
       "unique          3       2     2        2\n",
       "top     3rd class  adults   man       no\n",
       "freq          706    1207   869      817"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f70bcdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.replace([('1st class', 1), ('2nd class', 2), ('3rd class', 3), ('man', 0), ('woman', 1), ('yes', 1), ('no', 0)])\n",
    "df = df.replace(['1st class', '2nd class', '3rd class', 'man', 'women', 'yes', 'no', 'adults', 'child'], [1, 2, 3, 0, 1, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c03ffb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  age  sex  survived\n",
       "1      1    1    0         1\n",
       "2      1    1    0         1\n",
       "3      1    1    0         1\n",
       "4      1    1    0         1\n",
       "5      1    1    0         1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e172f0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1316 entries, 1 to 1316\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   class     1316 non-null   int64\n",
      " 1   age       1316 non-null   int64\n",
      " 2   sex       1316 non-null   int64\n",
      " 3   survived  1316 non-null   int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 51.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3bb4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5174aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='survived', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "15581f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99009398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14f96cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=123)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b9b15",
   "metadata": {},
   "source": [
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, class_names=clf.classes_, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25cca762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0634620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57281553, 0.42718447],\n",
       "       [0.85207101, 0.14792899],\n",
       "       [0.85207101, 0.14792899],\n",
       "       [0.85207101, 0.14792899],\n",
       "       [0.625     , 0.375     ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "954c9f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2e9b384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[443,  14],\n",
       "       [145, 134]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb90978c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    457\n",
       "1    279\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ec95223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  443   14\n",
       "1  145  134"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93b5be30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.97      0.85       457\n",
      "           1       0.91      0.48      0.63       279\n",
      "\n",
      "    accuracy                           0.78       736\n",
      "   macro avg       0.83      0.72      0.74       736\n",
      "weighted avg       0.81      0.78      0.76       736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "984990a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.81\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64ac7082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.98      0.87       196\n",
      "           1       0.95      0.53      0.68       120\n",
      "\n",
      "    accuracy                           0.81       316\n",
      "   macro avg       0.86      0.75      0.77       316\n",
      "weighted avg       0.84      0.81      0.79       316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Produce y_predictions that come from the X_validate\n",
    "y_pred = clf.predict(X_validate)\n",
    "\n",
    "# Compare actual y values (from validate) to predicted y_values from the model run on X_validate\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f57cee7",
   "metadata": {},
   "source": [
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, \n",
    "                           class_names=('Yes', 'No'), rounded=True, \n",
    "                           filled=True, out_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1680842",
   "metadata": {},
   "source": [
    "### Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5656c6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cca2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reduce obvious noise\n",
    "df = df.set_index(\"passenger_id\")\n",
    "df = df.drop(columns=[\"class\", \"embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3471bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop deck because there are far too many nulls\n",
    "df = df.drop(columns=[\"deck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0bfbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's fill embark_town with the most common observation\n",
    "df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47d58fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the distribution of values, it appears that no age subgroup is very close to the population\n",
    "# If we needed to be more certain, we could perform hypothesis testing\n",
    "# It looks like there's nothing wildly different about the no age group compared to the population\n",
    "# So we'll impute using the median age\n",
    "df.age = df.age.fillna(value=df.age.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f97c7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              survived  pclass   age  sibsp  parch     fare  alone  sex_male  \\\n",
       "passenger_id                                                                   \n",
       "0                    0       3  22.0      1      0   7.2500      0         1   \n",
       "1                    1       1  38.0      1      0  71.2833      0         0   \n",
       "2                    1       3  26.0      0      0   7.9250      1         0   \n",
       "3                    1       1  35.0      1      0  53.1000      0         0   \n",
       "4                    0       3  35.0      0      0   8.0500      1         1   \n",
       "\n",
       "              embark_town_Queenstown  embark_town_Southampton  \n",
       "passenger_id                                                   \n",
       "0                                  0                        1  \n",
       "1                                  0                        0  \n",
       "2                                  0                        1  \n",
       "3                                  0                        1  \n",
       "4                                  0                        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time to encode the encodeable!\n",
    "dummy_df = pd.get_dummies(df[['sex','embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "# Drop the original columns we encoded\n",
    "df = df.drop(columns=[\"sex\", \"embark_town\"])\n",
    "\n",
    "# Stitch the df and the dummy_df together again\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150caf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to split!\n",
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "340ed03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "835ddb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "# modeling\n",
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d7b22c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 1 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.820433</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.790217</td>\n",
       "      <td>0.797255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.696335</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.779764</td>\n",
       "      <td>0.799197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.797358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
       "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
       "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
       "support    307.000000  191.000000  0.799197  498.000000    498.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1 = tree1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = tree1.predict(X_train)\n",
    "\n",
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e19c88",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Continue working in your model file with titanic data to do the following:\n",
    "\n",
    "- 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "- 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "- 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "- 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "- 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "### After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15255dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e5a6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3cdd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to split!\n",
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ac5d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8853b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "# create a baseline using .mode()\n",
    "\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cf270e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random forest object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=1, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3a10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "799ff459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=1, random_state=123)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the random forest\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04c78311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2  0.06 0.04 0.04 0.12 0.11 0.39 0.   0.04]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate importance, or weight, of each feature.\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e9a34b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions\n",
    "y_pred = rf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96ca6c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64575062, 0.35424938],\n",
       "       [0.68303155, 0.31696845],\n",
       "       [0.68913723, 0.31086277],\n",
       "       [0.40559605, 0.59440395],\n",
       "       [0.42322053, 0.57677947]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate probability\n",
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19a8cd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Compute the Accuracy\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cca20e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[280  27]\n",
      " [ 82 109]]\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34031cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.84       307\n",
      "           1       0.80      0.57      0.67       191\n",
      "\n",
      "    accuracy                           0.78       498\n",
      "   macro avg       0.79      0.74      0.75       498\n",
      "weighted avg       0.78      0.78      0.77       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a classificaiton report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49dcd3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Out-of-Sample data\n",
    "\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c67b2d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  280   27\n",
       "1   82  109"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df2215df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 1 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.773481</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.787476</td>\n",
       "      <td>0.784216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.912052</td>\n",
       "      <td>0.570681</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.741366</td>\n",
       "      <td>0.781124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.837070</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.751868</td>\n",
       "      <td>0.771715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.773481    0.801471  0.781124    0.787476      0.784216\n",
       "recall       0.912052    0.570681  0.781124    0.741366      0.781124\n",
       "f1-score     0.837070    0.666667  0.781124    0.751868      0.771715\n",
       "support    307.000000  191.000000  0.781124  498.000000    498.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution example\n",
    "# Make the model\n",
    "forest1 = RandomForestClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1 = forest1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = forest1.predict(X_train)\n",
    "\n",
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af012d0b",
   "metadata": {},
   "source": [
    "# KNN Exercises\n",
    "\n",
    "### Continue working in your model file with the titanic dataset.\n",
    "\n",
    "- 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "- 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "- 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "- 4. Run through steps 2-4 setting k to 10\n",
    "\n",
    "- 5. Run through setps 2-4 setting k to 20\n",
    "\n",
    "- 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "- 7. Which model performs best on our out-of-sample data from validate?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15215ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dddaa8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a4e3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to split!\n",
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36d3b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4bb8a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = ['uniform', 'distance']\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5edc7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34b32072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on X_train\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "010ed2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate probabilities (if you need them)\n",
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0509aaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [0. , 1. ],\n",
       "       [0. , 1. ],\n",
       "       [0. , 1. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7aa512be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1004c0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[256  51]\n",
      " [ 52 139]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a5e928d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.731579</td>\n",
       "      <td>0.793173</td>\n",
       "      <td>0.781374</td>\n",
       "      <td>0.792973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.833876</td>\n",
       "      <td>0.727749</td>\n",
       "      <td>0.793173</td>\n",
       "      <td>0.780812</td>\n",
       "      <td>0.793173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.832520</td>\n",
       "      <td>0.729659</td>\n",
       "      <td>0.793173</td>\n",
       "      <td>0.781090</td>\n",
       "      <td>0.793069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.793173</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.831169    0.731579  0.793173    0.781374      0.792973\n",
       "recall       0.833876    0.727749  0.793173    0.780812      0.793173\n",
       "f1-score     0.832520    0.729659  0.793173    0.781090      0.793069\n",
       "support    307.000000  191.000000  0.793173  498.000000    498.000000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5c1c17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on X_validate \n",
    "y_pred = knn.predict(X_validate)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b54ba21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on validate set: 0.71\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3547018d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 5):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylim(0.90, 1)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,20,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "60b3566a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.705607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.686916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.752336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.705607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  train_accuracy  validate_accuracy\n",
       "0  1        0.993976           0.705607\n",
       "1  2        0.837349           0.686916\n",
       "2  3        0.833333           0.752336\n",
       "3  4        0.799197           0.705607"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d05af32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATwElEQVR4nO3df4wc93nf8fcnJ6o5Ja5pV3RRnWRQDmTWaoOI9kVx68axk7akk7qi0gaQ3LSuikRRayV2YRAVUxQ2UBQpwMSpiyo2VP9QkjpSFOtKCYWhk+I6cpu2ho6mYIqmDyFUW+JRseg6TFzhDFHUkz92Tz7SS3GH3OHuzr1fAMGb783wnp0d3gf7/c4+m6pCkqRhfc+4C5AkTReDQ5LUiMEhSWrE4JAkNWJwSJIauWTcBYzS5ZdfXlu3bh13GZI0Nfbv3/+NqtrS5JhOBcfWrVtZWloadxmSNDWSfK3pMU5VSZIaMTgkSY0YHJKkRgwOSVIjBockqZFO3VUlqdv2HVhh7+Iyx06scsXmWXbv2Mau7XPjLmvDMTgkTYV9B1bYs3CQ1ZOnAFg5scqehYMAhsdF5lSVpKmwd3H5pdBYs3ryFHsXl8dU0cZlcEiaCsdOrDYaV3sMDklT4YrNs43G1R6DQ9JU2L1jG7ObZk4bm900w+4d28ZU0cbl4rikqbC2AO5dVeNncEiaGru2zxkUE8CpKklSIwaHJKkRg0OS1IjBIUlqxOCQJDXiXVWSNgybJI6GwSFpQ7BJ4ug4VSVpQ7BJ4ugYHJI2BJskjo7BIWlDsEni6BgckjYEmySOjovjkjYEmySOjsEhacOwSeJoOFUlSWrE4JAkNWJwSJIaMTgkSY0YHJKkRgwOSVIj3o4r6aKwM213tPqKI8nOJMtJjiS5Y8D3dyd5vP/niSSnkrw6yVVJPpfkcJJDSd7bZp2S2rXWmXblxCrFdzrT7juwMu7SdB5aC44kM8CdwDuAa4Gbk1y7fp+q2ltV11XVdcAe4NGq+ibwAvD+qnoD8GbgPWceK2l62Jm2W9p8xXE9cKSqnqyq54F7gRteZv+bgXsAquqZqvpi/+tvAYcBX9NKU8rOtN3SZnDMAU+v2z7KWX75J7kM2AncP+B7W4HtwBfOcuytSZaSLB0/fvxCa5bUAjvTdkubwZEBY3WWfd8J/GF/muo7/0Dy/fTC5H1V9WeDDqyqu6pqvqrmt2zZckEFS2qHnWm7pc27qo4CV63bvhI4dpZ9b6I/TbUmySZ6ofGpqlpopUJJF4WdabulzeB4DLgmydXACr1weNeZOyV5JfBjwM+uGwvwceBwVX2oxRolXSR2pu2O1qaqquoF4HZgkd7i9n1VdSjJbUluW7frjcDDVfXcurG3AP8Y+PF1t+v+ZFu1SpKGl6qzLTtMn/n5+VpaWhp3GZI0NZLsr6r5JsfYckSS1IjBIUlqxOCQJDVicEiSGjE4JEmNGBySpEYMDklSIwaHJKkRg0OS1IjBIUlqxOCQJDVicEiSGjE4JEmNGBySpEYMDklSIwaHJKmRNj86VhqbfQdWJuLzrSeljgvVlccxKab9fBoc6px9B1bYs3CQ1ZOnAFg5scqehYMAF/U/56TUcaG68jgmRRfOp1NV6py9i8sv/adcs3ryFHsXlzdkHReqK49jUnThfBoc6pxjJ1YbjXe9jgvVlccxKbpwPg0Odc4Vm2cbjXe9jgvVlccxKbpwPg0Odc7uHduY3TRz2tjsphl279i2Ieu4UF15HJOiC+fTxXF1ztoC47jvWpmUOi5UVx7HpOjC+UxVjbuGkZmfn6+lpaVxlyFJUyPJ/qqab3KMU1WSpEYMDklSIwaHJKkRg0OS1IjBIUlqxNtxJ8i0Nz7TZPK60qgZHBOiC43PNHm8rtQGp6omRBcan2nyeF2pDQbHhOhC4zNNHq8rtcHgmBBdaHymyeN1pTYYHBOiC43PNHm8rtQGF8cnRBcan2nyeF2pDTY5lKQNzCaHkqTWtRocSXYmWU5yJMkdA76/O8nj/T9PJDmV5NXDHCtJGo/WgiPJDHAn8A7gWuDmJNeu36eq9lbVdVV1HbAHeLSqvjnMsZKk8WjzFcf1wJGqerKqngfuBW54mf1vBu45z2MlSRdJm8ExBzy9bvtof+y7JLkM2Ancfx7H3ppkKcnS8ePHL7hoSdLLa/N23AwYO9stXO8E/rCqvtn02Kq6C7gLendVNS1So2dTPanb2gyOo8BV67avBI6dZd+b+M40VdNjNUFsqid1X5tTVY8B1yS5Osml9MLhwTN3SvJK4MeAB5oeq8ljUz2p+4YKjiT3J/mpJEMHTVW9ANwOLAKHgfuq6lCS25Lctm7XG4GHq+q5cx077M/W+NhUT+q+YaeqPgLcAvzHJL8H3F1VXznXQVX1GeAzZ4x99Iztu4G7hzlWk++KzbOsDAgJm+pJ3THUK4iq+v2q+kfAG4GvAo8k+V9Jbkmyqc0CNV1sqid139BTT0n+EvBPgZ8DDgAfphckj7RSmabSru1z/MpP/yBzm2cJMLd5ll/56R90YVzqkKGmqpIsAH8V+G3gnVX1TP9bv5vEroI6za7tcwaF1GHDrnH8p6r674O+0bSroiRpug07VfWGJJvXNpK8Ksm/aKckSdIkGzY4fr6qTqxtVNWfAD/fSkWSpIk2bHB8T5KX2oD0u9de2k5JkqRJNuwaxyJwX5KP0usZdRvwUGtVSZIm1rDB8a+AXwD+Ob0GhA8DH2urKI2PDQonj8+JBhnndTFUcFTVi/TePf6RdsvRONmgcPL4nGiQcV8Xw/aquibJp5N8OcmTa3/aLk4Xlw0KJ4/PiQYZ93Ux7OL4J+m92ngBeDvwW/TeDKgOsUHh5PE50SDjvi6GDY7ZqvoskKr6WlV9EPjx9srSOJytEaENCsfH50SDjPu6GDY4vt1vqf5HSW5PciPwmhbr0hjYoHDy+JxokHFfF8PeVfU+4DLgl4B/S2+66t0t1aQxWVtU8w6eyeFzokHGfV2k6uU/prv/Zr9/X1W7L0pFF2B+fr6Wluy5KEnDSrK/ac/Bc05VVdUp4E3r3zkuSdq4hp2qOgA80P/0v/Uf8brQSlWSpIk1bHC8Gvh/nH4nVQEGhyRtMMO+c/yWtguRJE2HYT8B8JP0XmGcpqr+2cgrkiRNtGGnqv7buq+/F7gRODb6ciRJk27Yqar7128nuQf4/VYqkiRNtGHfOX6ma4DXjrIQSdJ0GHaN41ucvsbxx/Q+o0OStMEMO1X1irYLkSRNh2E/j+PGJK9ct705ya7WqpIkTaxh1zg+UFV/urZRVSeAD7RSkSRpog0bHIP2G/ZWXklShwwbHEtJPpTkB5K8LsmvA/vbLEySNJmGDY5fBJ4Hfhe4D1gF3tNWUZKkyTXsXVXPAXe0XIskaQoMe1fVI0k2r9t+VZLF1qqSJE2sYaeqLu/fSQVAVf0Jfua4JG1IwwbHi0leajGSZCsDuuVKkrpv2Ftq/zXwP5M82t9+K3BrOyVdfPsOrIztQ981mM+JNLmGXRx/KMk8vbB4HHiA3p1VU2/fgRX2LBxk9eQpAFZOrLJn4SCAv6jGxOdEmmzDLo7/HPBZ4P39P78NfLC9si6evYvLL/2CWrN68hR7F5fHVJF8TqTJNuwax3uBHwa+VlVvB7YDx891UJKdSZaTHEky8HbeJG9L8niSQ+umwkjyL/tjTyS5J8n3DllrI8dODH7hdLZxtc/nRJpswwbHt6vq2wBJ/kJVfQXY9nIHJJkB7gTeAVwL3Jzk2jP22Qz8BvD3q+qvAT/TH58DfgmYr6q/DswANw37oJq4YvNso3G1z+dEmmzDBsfR/i/5fcAjSR7g3B8dez1wpKqerKrngXuBG87Y513AQlU9BVBVz6773iXAbJJLgMuG+HnnZfeObcxumjltbHbTDLt3vGwuqkU+J9JkG3Zx/Mb+lx9M8jnglcBD5zhsDnh63fZR4EfO2Of1wKYkfwC8AvhwVf1WVa0k+VXgKXqL8A9X1cPD1NrU2mKrd/BMDp8TabI17nBbVY+eey8AMujwAT//TcBPALPA/07yf+itn9wAXA2cAH4vyc9W1X/5rh+S3Er/1uDXvvb8Ps121/Y5fylNGJ8TaXKd72eOD+MocNW67Sv57ummo8BDVfVcVX0D+DzwQ8DfBv5vVR2vqpPAAvA3B/2Qqrqrquaran7Lli0jfxCSpNO1GRyPAdckuTrJpfQWtx88Y58HgB9NckmSy+hNZR2mN0X15iSXJQm9VySHW6xVkjSk1j6MqapeSHI7sEjvrqhPVNWhJLf1v//Rqjqc5CHgS8CLwMeq6gmAJJ8Gvgi8ABwA7mqrVknS8FLVnZZT8/PztbS0NO4yJGlqJNlfVfNNjmlzqkqS1EF+brh0FjZa1CBeFwaHNJCNFjWI10WPU1XSADZa1CBeFz0GhzSAjRY1iNdFj8EhDWCjRQ3iddFjcEgD2GhRg3hd9Lg4Lg1go0UN4nXR4xsAJWkD8w2AkqTWGRySpEYMDklSIwaHJKkRg0OS1IjBIUlqxOCQJDVicEiSGjE4JEmNGBySpEYMDklSIwaHJKkRg0OS1IjBIUlqxOCQJDVicEiSGjE4JEmNGBySpEb8zPGO2XdgZcN/HrKkdhkcHbLvwAp7Fg6yevIUACsnVtmzcBDA8JA0Mk5VdcjexeWXQmPN6slT7F1cHlNFkrrI4OiQYydWG41L0vkwODrkis2zjcYl6XwYHB2ye8c2ZjfNnDY2u2mG3Tu2jakiSV3k4niHrC2Ae1eVpDYZHB2za/ucQSGpVU5VSZIaMTgkSY0YHJKkRgwOSVIjrQZHkp1JlpMcSXLHWfZ5W5LHkxxK8ui68c1JPp3kK0kOJ/kbbdYqSRpOa3dVJZkB7gT+DnAUeCzJg1X15XX7bAZ+A9hZVU8lec26f+LDwENV9Q+TXApc1latkqThtfmK43rgSFU9WVXPA/cCN5yxz7uAhap6CqCqngVI8heBtwIf748/X1UnWqxVkjSkNoNjDnh63fbR/th6rwdeleQPkuxP8k/6468DjgOfTHIgyceSfN+gH5Lk1iRLSZaOHz8+6scgSTpDm8GRAWN1xvYlwJuAnwJ2AP8myev7428EPlJV24HngIFrJFV1V1XNV9X8li1bRla8JGmwNoPjKHDVuu0rgWMD9nmoqp6rqm8Anwd+qD9+tKq+0N/v0/SCRJI0Zm0Gx2PANUmu7i9u3wQ8eMY+DwA/muSSJJcBPwIcrqo/Bp5Ostad7yeALyNJGrvW7qqqqheS3A4sAjPAJ6rqUJLb+t//aFUdTvIQ8CXgReBjVfVE/5/4ReBT/dB5ErilrVolScNL1ZnLDtNrfn6+lpaWxl2GJE2NJPurar7JMb5zXJLUiMEhSWrE4JAkNWJwSJIaMTgkSY0YHJKkRgwOSVIjBockqRGDQ5LUiMEhSWrE4JAkNWJwSJIaMTgkSY0YHJKkRgwOSVIjBockqRGDQ5LUiMEhSWrE4JAkNXLJuAvoin0HVti7uMyxE6tcsXmW3Tu2sWv73LjLkqSRMzhGYN+BFfYsHGT15CkAVk6ssmfhIIDhIalznKoagb2Lyy+FxprVk6fYu7g8pookqT0GxwgcO7HaaFySppnBMQJXbJ5tNC5J08zgGIHdO7Yxu2nmtLHZTTPs3rFtTBVJUntcHB+BtQVw76qStBEYHCOya/ucQSFpQ3CqSpLUiMEhSWrE4JAkNWJwSJIaMTgkSY2kqsZdw8gk+RZgn4/RuBz4xriL6BDP52h5PkdnW1W9oskBXbsdd7mq5sddRBckWfJcjo7nc7Q8n6OTZKnpMU5VSZIaMTgkSY10LTjuGncBHeK5HC3P52h5Pken8bns1OK4JKl9XXvFIUlqmcEhSWqkE8GRZGeS5SRHktwx7nqmXZKvJjmY5PHzuVVvo0vyiSTPJnli3dirkzyS5I/6f79qnDVOi7Ocyw8mWelfn48n+clx1jhNklyV5HNJDic5lOS9/fFG1+fUB0eSGeBO4B3AtcDNSa4db1Wd8Paqus575c/L3cDOM8buAD5bVdcAn+1v69zu5rvPJcCv96/P66rqMxe5pmn2AvD+qnoD8GbgPf3fl42uz6kPDuB64EhVPVlVzwP3AjeMuSZtYFX1eeCbZwzfAPxm/+vfBHZdzJqm1VnOpc5TVT1TVV/sf/0t4DAwR8PrswvBMQc8vW77aH9M56+Ah5PsT3LruIvpiL9cVc9A7z8v8Jox1zPtbk/ypf5UltN+5yHJVmA78AUaXp9dCI4MGPMe4wvzlqp6I73pv/ckeeu4C5LW+QjwA8B1wDPAr421mimU5PuB+4H3VdWfNT2+C8FxFLhq3faVwLEx1dIJVXWs//ezwH+lNx2oC/P1JH8FoP/3s2OuZ2pV1der6lRVvQj8Z7w+G0myiV5ofKqqFvrDja7PLgTHY8A1Sa5OcilwE/DgmGuaWkm+L8kr1r4G/i7wxMsfpSE8CLy7//W7gQfGWMtUW/sF13cjXp9DSxLg48DhqvrQum81uj478c7x/u14/wGYAT5RVf9uvBVNrySvo/cqA3rdk3/H89lMknuAt9Fr/f114APAPuA+4LXAU8DPVJWLvudwlnP5NnrTVAV8FfiFtfl5vbwkfwv4H8BB4MX+8C/TW+cY+vrsRHBIki6eLkxVSZIuIoNDktSIwSFJasTgkCQ1YnBIkhoxOKQWJdm6vrOr1AUGhySpEYNDukiSvC7JgSQ/PO5apAthcEgXQZJt9PoD3VJVj427HulCXDLuAqQNYAu93j//oKoOjbsY6UL5ikNq35/S+8yYt4y7EGkUfMUhte95ep+otpjk/1fV74y5HumCGBzSRVBVzyX5e8AjSZ6rKtuqa2rZHVeS1IhrHJKkRgwOSVIjBockqRGDQ5LUiMEhSWrE4JAkNWJwSJIa+XOoQM5B2sUz7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0c0f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = ['uniform', 'distance']\n",
    "# setting to 10\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d933109f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e91464f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on X_train\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "195b49fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0.7],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.5, 0.5],\n",
       "       [0.2, 0.8],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.7, 0.3],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0. , 1. ],\n",
       "       [0.5, 0.5],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.7, 0.3],\n",
       "       [0.5, 0.5],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.5, 0.5],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.1, 0.9],\n",
       "       [0.4, 0.6],\n",
       "       [0.5, 0.5],\n",
       "       [0.7, 0.3],\n",
       "       [0.5, 0.5],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.1, 0.9],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0.4, 0.6],\n",
       "       [0.3, 0.7],\n",
       "       [0.9, 0.1],\n",
       "       [0.3, 0.7],\n",
       "       [0.9, 0.1],\n",
       "       [0.5, 0.5],\n",
       "       [0.8, 0.2],\n",
       "       [0.9, 0.1],\n",
       "       [0.5, 0.5],\n",
       "       [0.8, 0.2],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.9, 0.1],\n",
       "       [0.7, 0.3],\n",
       "       [0.7, 0.3],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0.7, 0.3],\n",
       "       [0.5, 0.5],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.1, 0.9],\n",
       "       [0.9, 0.1],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.3, 0.7],\n",
       "       [0.3, 0.7],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.3, 0.7],\n",
       "       [0.9, 0.1],\n",
       "       [0.7, 0.3],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.3, 0.7],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.5, 0.5],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.3, 0.7],\n",
       "       [0.8, 0.2],\n",
       "       [0.7, 0.3],\n",
       "       [0.4, 0.6],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0.3, 0.7],\n",
       "       [0.6, 0.4],\n",
       "       [0.5, 0.5],\n",
       "       [0.3, 0.7],\n",
       "       [0.5, 0.5],\n",
       "       [0.4, 0.6],\n",
       "       [0.7, 0.3],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.7, 0.3],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.3, 0.7],\n",
       "       [0.3, 0.7],\n",
       "       [0.3, 0.7],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [0.7, 0.3],\n",
       "       [0.5, 0.5],\n",
       "       [0.6, 0.4],\n",
       "       [0.3, 0.7],\n",
       "       [0.3, 0.7],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.5, 0.5],\n",
       "       [0.9, 0.1],\n",
       "       [0.7, 0.3],\n",
       "       [0.1, 0.9],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.7, 0.3],\n",
       "       [0.9, 0.1],\n",
       "       [0.7, 0.3],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3],\n",
       "       [0.3, 0.7],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.3, 0.7],\n",
       "       [0.7, 0.3],\n",
       "       [0.5, 0.5],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.1, 0.9],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.3, 0.7],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [0.3, 0.7],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.9, 0.1],\n",
       "       [0.7, 0.3],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.3, 0.7],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.7, 0.3],\n",
       "       [0.9, 0.1],\n",
       "       [0.7, 0.3],\n",
       "       [0.1, 0.9],\n",
       "       [1. , 0. ],\n",
       "       [0.9, 0.1],\n",
       "       [0.7, 0.3],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.5, 0.5],\n",
       "       [0.9, 0.1],\n",
       "       [1. , 0. ],\n",
       "       [0.7, 0.3],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.9, 0.1],\n",
       "       [0.5, 0.5],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [0.2, 0.8],\n",
       "       [0.9, 0.1],\n",
       "       [0.3, 0.7],\n",
       "       [0.8, 0.2],\n",
       "       [0.9, 0.1],\n",
       "       [0.4, 0.6],\n",
       "       [0.7, 0.3],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.5, 0.5],\n",
       "       [0.6, 0.4],\n",
       "       [0.1, 0.9],\n",
       "       [0.4, 0.6],\n",
       "       [0.3, 0.7],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.1, 0.9],\n",
       "       [0.3, 0.7],\n",
       "       [0.9, 0.1],\n",
       "       [0.5, 0.5],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3],\n",
       "       [0.1, 0.9],\n",
       "       [0.9, 0.1],\n",
       "       [0.7, 0.3],\n",
       "       [0.5, 0.5],\n",
       "       [0.7, 0.3],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [1. , 0. ],\n",
       "       [0.5, 0.5],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.9, 0.1],\n",
       "       [0.1, 0.9],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.5, 0.5],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.1, 0.9],\n",
       "       [0.5, 0.5],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [0.3, 0.7],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3],\n",
       "       [0.2, 0.8],\n",
       "       [0.1, 0.9],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.9, 0.1],\n",
       "       [0.8, 0.2],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.7, 0.3],\n",
       "       [0.7, 0.3],\n",
       "       [0.2, 0.8],\n",
       "       [0.3, 0.7],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.9, 0.1],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.3, 0.7],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3],\n",
       "       [0.8, 0.2],\n",
       "       [0.1, 0.9],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.9, 0.1],\n",
       "       [1. , 0. ],\n",
       "       [0.7, 0.3],\n",
       "       [0.4, 0.6],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.3, 0.7],\n",
       "       [0.5, 0.5],\n",
       "       [0.1, 0.9],\n",
       "       [0.4, 0.6],\n",
       "       [0.7, 0.3],\n",
       "       [0.9, 0.1],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.3, 0.7],\n",
       "       [0.9, 0.1],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.5, 0.5],\n",
       "       [0.8, 0.2],\n",
       "       [0.3, 0.7],\n",
       "       [0.9, 0.1],\n",
       "       [0.5, 0.5],\n",
       "       [1. , 0. ],\n",
       "       [0.9, 0.1],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [0.7, 0.3],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [0.1, 0.9],\n",
       "       [0.3, 0.7],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.1, 0.9],\n",
       "       [0.5, 0.5],\n",
       "       [0.9, 0.1],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3],\n",
       "       [0.3, 0.7],\n",
       "       [0.9, 0.1],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.9, 0.1],\n",
       "       [0.8, 0.2],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [0.1, 0.9],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.9, 0.1],\n",
       "       [1. , 0. ],\n",
       "       [0.7, 0.3],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [0.9, 0.1],\n",
       "       [0.2, 0.8],\n",
       "       [0.1, 0.9],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3],\n",
       "       [0.7, 0.3],\n",
       "       [0.3, 0.7],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.1, 0.9],\n",
       "       [0.6, 0.4],\n",
       "       [0.1, 0.9],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.9, 0.1],\n",
       "       [0.9, 0.1],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.3, 0.7],\n",
       "       [0.7, 0.3],\n",
       "       [0.1, 0.9],\n",
       "       [0.5, 0.5],\n",
       "       [0.1, 0.9],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.3, 0.7],\n",
       "       [0.7, 0.3],\n",
       "       [0.7, 0.3],\n",
       "       [0.9, 0.1],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.7, 0.3],\n",
       "       [0.7, 0.3],\n",
       "       [0.6, 0.4],\n",
       "       [0.7, 0.3]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate probabilities (if you need them)\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2fb2600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2eb1beb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[276  31]\n",
      " [ 95  96]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19a0a650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.743935</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.749920</td>\n",
       "      <td>0.748526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.899023</td>\n",
       "      <td>0.502618</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.700820</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.708966</td>\n",
       "      <td>0.733469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.743935    0.755906  0.746988    0.749920      0.748526\n",
       "recall       0.899023    0.502618  0.746988    0.700820      0.746988\n",
       "f1-score     0.814159    0.603774  0.746988    0.708966      0.733469\n",
       "support    307.000000  191.000000  0.746988  498.000000    498.000000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75002655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on X_validate \n",
    "y_pred = knn.predict(X_validate)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f068c1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on validate set: 0.71\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on validate set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b34e5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 10):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylim(0.90, 1)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,20,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5dc46392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.705607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.686916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.752336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.705607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.793173</td>\n",
       "      <td>0.705607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.769076</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.714953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.744980</td>\n",
       "      <td>0.728972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.700935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  train_accuracy  validate_accuracy\n",
       "0  1        0.993976           0.705607\n",
       "1  2        0.837349           0.686916\n",
       "2  3        0.833333           0.752336\n",
       "3  4        0.799197           0.705607\n",
       "4  5        0.793173           0.705607\n",
       "5  6        0.769076           0.719626\n",
       "6  7        0.765060           0.714953\n",
       "7  8        0.744980           0.728972\n",
       "8  9        0.765060           0.700935"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e50ab6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = ['uniform', 'distance']\n",
    "# change to 20\n",
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d27b4ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=20)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b65ff1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on X_train\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ef781b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55, 0.45],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.45, 0.55],\n",
       "       [0.65, 0.35],\n",
       "       [0.85, 0.15],\n",
       "       [0.6 , 0.4 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.45, 0.55],\n",
       "       [0.55, 0.45],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.85, 0.15],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.85, 0.15],\n",
       "       [0.45, 0.55],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.45, 0.55],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.45, 0.55],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.45, 0.55],\n",
       "       [0.45, 0.55],\n",
       "       [0.85, 0.15],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.65, 0.35],\n",
       "       [1.  , 0.  ],\n",
       "       [0.45, 0.55],\n",
       "       [0.65, 0.35],\n",
       "       [0.35, 0.65],\n",
       "       [0.65, 0.35],\n",
       "       [1.  , 0.  ],\n",
       "       [0.35, 0.65],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.85, 0.15],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.25, 0.75],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.25, 0.75],\n",
       "       [1.  , 0.  ],\n",
       "       [0.85, 0.15],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.95, 0.05],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.95, 0.05],\n",
       "       [0.55, 0.45],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.55, 0.45],\n",
       "       [0.25, 0.75],\n",
       "       [0.75, 0.25],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.25, 0.75],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.85, 0.15],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.8 , 0.2 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.45, 0.55],\n",
       "       [0.55, 0.45],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.95, 0.05],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.45, 0.55],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.95, 0.05],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.65, 0.35],\n",
       "       [0.15, 0.85],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.85, 0.15],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.35, 0.65],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.85, 0.15],\n",
       "       [0.45, 0.55],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.35, 0.65],\n",
       "       [0.95, 0.05],\n",
       "       [0.35, 0.65],\n",
       "       [0.6 , 0.4 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.95, 0.05],\n",
       "       [0.85, 0.15],\n",
       "       [0.85, 0.15],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.65, 0.35],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.65, 0.35],\n",
       "       [0.95, 0.05],\n",
       "       [0.95, 0.05],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.85, 0.15],\n",
       "       [0.45, 0.55],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.95, 0.05],\n",
       "       [0.65, 0.35],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.55, 0.45],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.45, 0.55],\n",
       "       [0.85, 0.15],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.25, 0.75],\n",
       "       [0.45, 0.55],\n",
       "       [0.45, 0.55],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.95, 0.05],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [1.  , 0.  ],\n",
       "       [0.35, 0.65],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.85, 0.15],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.35, 0.65],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.65, 0.35],\n",
       "       [1.  , 0.  ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.6 , 0.4 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.25, 0.75],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.65, 0.35],\n",
       "       [0.15, 0.85],\n",
       "       [0.95, 0.05],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.85, 0.15],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.25, 0.75],\n",
       "       [0.95, 0.05],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.75, 0.25],\n",
       "       [0.65, 0.35],\n",
       "       [0.75, 0.25],\n",
       "       [0.45, 0.55],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.7 , 0.3 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.15, 0.85],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.65, 0.35],\n",
       "       [0.65, 0.35],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.35, 0.65],\n",
       "       [0.95, 0.05],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.25, 0.75],\n",
       "       [0.85, 0.15],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.45, 0.55],\n",
       "       [0.55, 0.45],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.85, 0.15],\n",
       "       [0.35, 0.65],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.95, 0.05],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.95, 0.05],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.75, 0.25],\n",
       "       [0.55, 0.45],\n",
       "       [0.75, 0.25]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate probabilities (if you need them)\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f050d53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.72\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "145ba572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[269  38]\n",
      " [103  88]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "95c65492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.723118</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.710765</td>\n",
       "      <td>0.713643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.876221</td>\n",
       "      <td>0.460733</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.668477</td>\n",
       "      <td>0.716867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.792342</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.673773</td>\n",
       "      <td>0.701392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.723118    0.698413  0.716867    0.710765      0.713643\n",
       "recall       0.876221    0.460733  0.716867    0.668477      0.716867\n",
       "f1-score     0.792342    0.555205  0.716867    0.673773      0.701392\n",
       "support    307.000000  191.000000  0.716867  498.000000    498.000000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fd838637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 20):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylim(0.90, 1)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,20,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "422fbd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.705607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.686916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.752336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.705607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.793173</td>\n",
       "      <td>0.705607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.769076</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.714953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.744980</td>\n",
       "      <td>0.728972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.700935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.710280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.748996</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>0.724299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>0.724299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.724900</td>\n",
       "      <td>0.738318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.738956</td>\n",
       "      <td>0.738318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.728972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.726908</td>\n",
       "      <td>0.714953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.738318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.720884</td>\n",
       "      <td>0.728972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k  train_accuracy  validate_accuracy\n",
       "0    1        0.993976           0.705607\n",
       "1    2        0.837349           0.686916\n",
       "2    3        0.833333           0.752336\n",
       "3    4        0.799197           0.705607\n",
       "4    5        0.793173           0.705607\n",
       "5    6        0.769076           0.719626\n",
       "6    7        0.765060           0.714953\n",
       "7    8        0.744980           0.728972\n",
       "8    9        0.765060           0.700935\n",
       "9   10        0.746988           0.710280\n",
       "10  11        0.748996           0.719626\n",
       "11  12        0.740964           0.724299\n",
       "12  13        0.736948           0.724299\n",
       "13  14        0.724900           0.738318\n",
       "14  15        0.738956           0.738318\n",
       "15  16        0.734940           0.728972\n",
       "16  17        0.726908           0.714953\n",
       "17  18        0.734940           0.738318\n",
       "18  19        0.720884           0.728972"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d0646788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e517473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_univariate(train, cat_vars, quant_vars):\n",
    "    for var in cat_vars:\n",
    "        explore_univariate_categorical(train, var)\n",
    "        print('_________________________________________________________________')\n",
    "    for col in quant_vars:\n",
    "        p, descriptive_stats = explore_univariate_quant(train, col)\n",
    "        plt.show(p)\n",
    "        print(descriptive_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "296bb579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.explore_univariate(train, cat_vars, quant_vars)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c59b63bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2  0.06 0.04 0.04 0.12 0.11 0.39 0.   0.04]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15496fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
